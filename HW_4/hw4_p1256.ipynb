{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "# main_dir = 'C:\\\\Users\\\\gkhadge\\\\Documents\\\\UCLA\\\\EE232E\\\\HW_4'\n",
    "# os.chdir(main_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data_directory = \"/Users/Yusi/Documents/EE232E/HW_4/finance_data/data\"\n",
    "main_dir = '/Users/Yusi/Documents/EE232E/HW_4/'\n",
    "\n",
    "os.chdir(main_dir)\n",
    "data_directory = \"finance_data/data\"\n",
    "os.chdir(data_directory)\n",
    "\n",
    "close_data = {}\n",
    "end_date_data = {}\n",
    "date_data = {}\n",
    "\n",
    "for root,dirs,files in os.walk(os.path.join(main_dir, data_directory)):\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            with open(file) as f:\n",
    "                #cf = csv.DictReader(f, fieldnames=[\"Close\"])\n",
    "                cf = csv.reader(f)\n",
    "                stock_name = file[:-4]\n",
    "                #cf.next()\n",
    "                data = pandas.read_csv(file)\n",
    "                close_data[stock_name] = data[\"Close\"].values\n",
    "                end_date_data[stock_name] = [data[\"Date\"].values[0], data[\"Date\"].values[-1]]\n",
    "                \n",
    "                # Parse into datetime format\n",
    "                if stock_name[-2:] == '.B':\n",
    "                    date_format = '%x'\n",
    "                else:\n",
    "                    date_format = '%Y-%m-%d'\n",
    "                dates = [datetime.strptime(data[\"Date\"].values[i], date_format) for i in range(len(data[\"Date\"].values))]\n",
    "                \n",
    "                date_data[stock_name] = dates\n",
    "                \n",
    "\n",
    "            f.close()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# stock_names = close_data.keys();\n",
    "\n",
    "# for i in range(len(stock_names)):\n",
    "#     if end_date_data[stock_names[i]][0] != '2014-05-01':\n",
    "#         print(stock_names[i])\n",
    "# #     if end_date_data[stock_names[i]][1] != '2017-05-12':\n",
    "# #         print(stock_names[i])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# r_i = np.diff(np.log(close_data['A']))\n",
    "# r_j = np.diff(np.log(close_data['AAL']))\n",
    "\n",
    "# # p_ij_n = (np.dot(r_i,r_j)/len(r_i) - np.mean(r_i)*np.mean(r_j))\n",
    "# # p_ij_d = np.sqrt(np.var(r_i) * np.var(r_j))\n",
    "# #p_ij_d = (np.sqrt((np.mean(np.square(r_i))-np.square(np.mean(r_i)))*(np.mean(np.square(r_j))-np.square(np.mean(r_j))))\n",
    "\n",
    "# p_ij = (np.dot(r_i,r_j)/len(r_i) - np.mean(r_i)*np.mean(r_j))/ (np.sqrt(np.var(r_i) * np.var(r_j)))\n",
    "# print(p_ij)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Correlation Graph for Daily Data\n",
    "os.chdir(main_dir)\n",
    "StockNetworkFile = \"StockNetworkFile.txt\"\n",
    "\n",
    "f = open(StockNetworkFile, 'w')\n",
    "\n",
    "\n",
    "stock_names = close_data.keys();\n",
    "num_stocks = len(stock_names)\n",
    "\n",
    "d_ij_hist = np.zeros(int(num_stocks*(num_stocks-1)/2.0), dtype=np.float)\n",
    "p_ij = np.zeros(int(num_stocks*(num_stocks-1)/2.0), dtype=np.float)\n",
    "\n",
    "ind = 0\n",
    "\n",
    "for i in range(num_stocks):\n",
    "    # Loop over all stocks\n",
    "    stock_i = stock_names[i]\n",
    "    for j in range(i+1,num_stocks):\n",
    "        \n",
    "        stock_j = stock_names[j]\n",
    "        \n",
    "        r_i = np.diff(np.log(close_data[stock_i]))\n",
    "        r_j = np.diff(np.log(close_data[stock_j]))\n",
    "        \n",
    "        if len(r_i) != len(r_j):\n",
    "            min_len = min(len(r_i),len(r_j))     # calculate the minimum length of r_i and r_k\n",
    "\n",
    "            r_i = r_i[-min_len:] # since all stocks end at the same date, delete non-corresponding time values from the longer data set\n",
    "            r_j = r_j[-min_len:]\n",
    "\n",
    "#         print(len(r_i))\n",
    "#         print(len(r_j))\n",
    "#         print(stock_j)\n",
    "        p_ij[ind] = (np.dot(r_i,r_j)/len(r_i) - np.mean(r_i)*np.mean(r_j))/ (np.sqrt(np.var(r_i) * np.var(r_j)))\n",
    "        \n",
    "        d_ij = np.sqrt(2*(1-p_ij[ind]))\n",
    "        d_ij_hist[ind] = d_ij\n",
    "        \n",
    "        ind = ind+1\n",
    "        \n",
    "        f.write(stock_i+\"\\t\"+stock_j+\"\\t\"+(\"%.15f\" % d_ij)+\"\\n\")\n",
    "\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "date_data['ZTS'][7].weekday()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Correlation Graph for Weekly Data\n",
    "os.chdir(main_dir)\n",
    "StockNetworkFile = \"StockNetworkFile_Weekly.txt\"\n",
    "\n",
    "f = open(StockNetworkFile, 'w')\n",
    "\n",
    "stock_names = close_data.keys();\n",
    "num_stocks = len(stock_names)\n",
    "\n",
    "d_ij_hist = np.zeros(int(num_stocks*(num_stocks-1)/2.0), dtype=np.float)\n",
    "p_ij = np.zeros(int(num_stocks*(num_stocks-1)/2.0), dtype=np.float)\n",
    "\n",
    "ind = 0\n",
    "\n",
    "for i in range(num_stocks):\n",
    "    # Loop over all stocks\n",
    "    stock_i = stock_names[i]\n",
    "    for j in range(i+1,num_stocks):\n",
    "        \n",
    "        stock_j = stock_names[j]\n",
    "        \n",
    "        start_day_i = 0;\n",
    "        start_day_j = 0;\n",
    "        while date_data[stock_i][start_day_i] < date_data[stock_j][start_day_j]:\n",
    "            start_day_i += 1\n",
    "        \n",
    "        while date_data[stock_i][start_day_i] > date_data[stock_j][start_day_j]:\n",
    "            start_day_j += 1\n",
    "            \n",
    "        weekly_log_close_i = []\n",
    "        weekly_log_close_j = []\n",
    "        \n",
    "        day = 0\n",
    "        \n",
    "        curr_day = -1\n",
    "        while start_day_i + day < len(date_data[stock_i]) and start_day_j + day < len(date_data[stock_j]):\n",
    "            prev_day = curr_day\n",
    "            curr_day = date_data[stock_i][start_day_i + day].weekday()\n",
    "            \n",
    "            # If Monday, or Tuesday with Monday being a holiday\n",
    "            if curr_day == 0 or (curr_day == 1 and prev_day == 4):\n",
    "                weekly_log_close_i.append(np.log(close_data[stock_i][start_day_i + day]))\n",
    "                weekly_log_close_j.append(np.log(close_data[stock_j][start_day_j + day]))\n",
    "            \n",
    "            day += 1\n",
    "        \n",
    "        r_i = np.diff(weekly_log_close_i)\n",
    "        r_j = np.diff(weekly_log_close_j)\n",
    "        \n",
    "\n",
    "#         print(len(r_i))\n",
    "#         print(len(r_j))\n",
    "#         print(stock_j)\n",
    "        p_ij[ind] = (np.dot(r_i,r_j)/len(r_i) - np.mean(r_i)*np.mean(r_j))/ (np.sqrt(np.var(r_i) * np.var(r_j)))\n",
    "        \n",
    "        d_ij = np.sqrt(2*(1-p_ij[ind]))\n",
    "        d_ij_hist[ind] = d_ij\n",
    "        \n",
    "        ind = ind+1\n",
    "        \n",
    "        f.write(stock_i+\"\\t\"+stock_j+\"\\t\"+(\"%.15f\" % d_ij)+\"\\n\")\n",
    "\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# the histogram of the data\n",
    "n, bins, patches = plt.hist(d_ij_hist, 100, normed=1, alpha = 0.75)\n",
    "\n",
    "plt.xlabel('D_ij Value')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('D_ij Histogram')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Problem 7: Modifying Correlation\n",
    "os.chdir(main_dir)\n",
    "StockNetworkFileMod = \"StockNetworkFileMod.txt\"\n",
    "\n",
    "f = open(StockNetworkFileMod, 'w')\n",
    "\n",
    "# open new file to save d_ij\n",
    "d_ij_hist_mod = np.zeros(int(num_stocks*(num_stocks-1)/2.0), dtype=np.float)\n",
    "p_ij_mod = np.zeros(int(num_stocks*(num_stocks-1)/2.0), dtype=np.float)\n",
    "\n",
    "ind = 0\n",
    "\n",
    "for i in range(num_stocks):\n",
    "    # Loop over all stocks\n",
    "    stock_i = stock_names[i]\n",
    "    for j in range(i+1,num_stocks):\n",
    "        \n",
    "        stock_j = stock_names[j]\n",
    "        \n",
    "        r_i = np.diff(np.log(close_data[stock_i]))\n",
    "        r_j = np.diff(np.log(close_data[stock_j]))\n",
    "        \n",
    "        if len(r_i) != len(r_j):\n",
    "            min_len = min(len(r_i),len(r_j))     # calculate the minimum length of r_i and r_k\n",
    "\n",
    "            r_i = r_i[-min_len:] # since all stocks end at the same date, delete non-corresponding time values from the longer data set\n",
    "            r_j = r_j[-min_len:]\n",
    "\n",
    "#         print(len(r_i))\n",
    "#         print(len(r_j))\n",
    "#         print(stock_j)\n",
    "        p_ij_mod[ind] = (np.dot(r_i,r_j)/len(r_i) - np.mean(r_i)*np.mean(r_j))/ (np.sqrt(np.var(r_i) * np.var(r_j)))\n",
    "        \n",
    "        if p_ij_mod[ind] > 0.3:\n",
    "            p_ij_mod[ind] = -1\n",
    "        \n",
    "        d_ij_mod = np.sqrt(2*(1-p_ij_mod[ind]))\n",
    "        d_ij_hist_mod[ind] = d_ij_mod\n",
    "        \n",
    "        ind = ind + 1\n",
    "        \n",
    "        f.write(stock_i+\"\\t\"+stock_j+\"\\t\"+(\"%.15f\" % d_ij_mod)+\"\\n\")\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the histogram of the data\n",
    "n, bins, patches = plt.hist(d_ij_hist_mod, 100, normed=1, alpha = 0.75)\n",
    "\n",
    "plt.xlabel('D_ij Modified Value')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('D_ij Modified Histogram')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Eulerian Path Function\n",
    "from collections import defaultdict\n",
    "\n",
    "def find_euler_tour(graph):\n",
    "    tour = []\n",
    "    E = graph\n",
    "\n",
    "    numEdges = defaultdict(int)\n",
    "\n",
    "    def find_tour(u):\n",
    "        for e in E:\n",
    "            if u == e[0]:\n",
    "                u,v = e\n",
    "                E.remove(e)\n",
    "                find_tour(v)\n",
    "            elif u == e[1]:\n",
    "                v,u = e\n",
    "                E.remove(e)\n",
    "                find_tour(v)\n",
    "        tour.insert(0,u)\n",
    "\n",
    "    for i,j in graph:\n",
    "        numEdges[i] += 1\n",
    "        numEdges[j] += 1\n",
    "\n",
    "    start = graph[0][0]\n",
    "    for i,j in numEdges.iteritems():\n",
    "        if j % 2 > 0:\n",
    "            start = i\n",
    "            break\n",
    "\n",
    "    current = start\n",
    "    find_tour(current)\n",
    "\n",
    "    if tour[0] != tour[-1]:\n",
    "        return None\n",
    "    return tour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MST Weight: 426.37\n",
      "TSP Approx: 485.38\n"
     ]
    }
   ],
   "source": [
    "# PROBLEM 5 TSP Approximation using Eulerian Path Method\n",
    "os.chdir(main_dir)\n",
    "\n",
    "sys.setrecursionlimit(1500)\n",
    "\n",
    "# Load MST\n",
    "with open('StockNetwork_MST.txt', 'rb') as f:\n",
    "    reader = csv.reader(f, delimiter=' ')\n",
    "    g_mst = list(reader)\n",
    "    \n",
    "# Sum MST weight, and remove edgeweights for find_euler_tour\n",
    "MST_weight = 0\n",
    "for i in range(len(g_mst)):\n",
    "    MST_weight += float(g_mst[i][2])\n",
    "    g_mst[i] = g_mst[i][0:2]\n",
    "    \n",
    "# Double the edges\n",
    "g_mst_doubled = g_mst + g_mst\n",
    "\n",
    "# Find Eulerian tour\n",
    "etour = find_euler_tour(g_mst_doubled)\n",
    "\n",
    "# Remove duplicate nodes to create TSP approximation\n",
    "TSP_approx = [];\n",
    "for i in etour:\n",
    "  if i not in TSP_approx:\n",
    "    TSP_approx.append(i)\n",
    "# Make the TSP end at the starting node\n",
    "TSP_approx.append(etour[0])\n",
    "\n",
    "# Open the full graph\n",
    "with open('StockNetworkFile.txt', 'rb') as f:\n",
    "    reader = csv.reader(f, delimiter='\\t')\n",
    "    g = list(reader)\n",
    "\n",
    "# Create dictionary of edge weights. keys are node1_node2 where node1 is alphabetically earlier\n",
    "edgedict = {}\n",
    "for edge in g:\n",
    "    if edge[0] < edge[1]:\n",
    "        key = edge[0]+'_'+edge[1]\n",
    "    else:\n",
    "        key = edge[1]+'_'+edge[0]\n",
    "    edgedict[key] = float(edge[2])\n",
    "    \n",
    "# Sum edgeweights along TSP approx route\n",
    "TSP_approx_value = 0\n",
    "for i in range(len(TSP_approx)-1):\n",
    "    node0 = TSP_approx[i]\n",
    "    node1 = TSP_approx[i+1]\n",
    "    if node0 < node1:\n",
    "        edge = node0+'_'+node1\n",
    "    else:\n",
    "        edge = node1+'_'+node0\n",
    "    TSP_approx_value += edgedict[edge]    \n",
    "\n",
    "print \"MST Weight: {:0.2f}\".format(MST_weight)\n",
    "print \"TSP Approx: {:0.2f}\".format(TSP_approx_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Triangle Inequality Check\n",
    "\n",
    "stock_names = close_data.keys();\n",
    "num_stocks = len(stock_names)\n",
    "\n",
    "violation_count = 0\n",
    "itr = 0\n",
    "\n",
    "for i in range(num_stocks):   # iterate through all possible starting nodes\n",
    "    itr = itr+1\n",
    "    stock_i = stock_names[i]\n",
    "    print(itr)\n",
    "    for j in range(i+1,num_stocks):    # iterate through all ending nodes\n",
    "        stock_j = stock_names[j]\n",
    "        if stock_j != stock_i:      # make sure that the stocks are distinct\n",
    "            if stock_i < stock_j\n",
    "                key_ij = stock_i+'_'+stock_j     # keys are alphabetical\n",
    "            else:\n",
    "                key_ij = stock_j+'_'+stock_i\n",
    "            l_ij = edgedict[key_ij]\n",
    "            for k in range(num_stocks):      # iterate through all intermediate nodes\n",
    "                stock_k = stock_names[k]\n",
    "                \n",
    "                if (stock_k != stock_i) and (stock_k != stock_j):      # make sure that the stocks are distinct\n",
    "                    if stock_k < stock_j:\n",
    "                        key_jk = stock_k+'_'+stock_j\n",
    "                    else:\n",
    "                        key_jk = stock_j+'_'+stock_k\n",
    "\n",
    "                    if stock_k < stock_i:\n",
    "                        key_ik = stock_k+'_'+stock_i\n",
    "                    else:\n",
    "                        key_ik = stock_i+'_'+stock_k\n",
    "                        \n",
    "                    l_ik = edgedict[key_ik]\n",
    "                    l_jk = edgedict[key_jk]\n",
    "                    \n",
    "    if (l_jk + l_ik < l_ij):\n",
    "        violation_count = violation_count+1\n",
    "        \n",
    "print(violation_count)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
